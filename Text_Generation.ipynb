{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7549dbe6-7b42-4c34-a3df-1ff03149b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "rown fox jumps over the dog. \n",
      "   the quick brown fox runs swiftly.\n",
      "   the lazy dog sleeps while the \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "class MarkovTextGenerator:\n",
    "    def __init__(self, order=3):\n",
    "        \"\"\"\n",
    "        Initialize Markov chain generator.\n",
    "        order: number of characters to consider for each state (n-gram size)\n",
    "        \"\"\"\n",
    "        self.order = order\n",
    "        self.model = defaultdict(list)\n",
    "    \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the model on input text by building transition probabilities.\n",
    "        \"\"\"\n",
    "        # Clean text: convert to lowercase and remove special characters\n",
    "        text = re.sub(r'[^a-zA-Z\\s.,!?]', '', text.lower())\n",
    "        \n",
    "        # Build the Markov chain\n",
    "        for i in range(len(text) - self.order):\n",
    "            state = text[i:i + self.order]\n",
    "            next_char = text[i + self.order]\n",
    "            self.model[state].append(next_char)\n",
    "    \n",
    "    def generate(self, length=100, seed=None):\n",
    "        \"\"\"\n",
    "        Generate text of specified length.\n",
    "        seed: starting sequence (must be of length order)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            return \"Model not trained. Please train with text first.\"\n",
    "        \n",
    "        # Choose random seed if none provided\n",
    "        if seed is None:\n",
    "            seed = random.choice(list(self.model.keys()))\n",
    "        \n",
    "        # Ensure seed is valid\n",
    "        if len(seed) != self.order or seed not in self.model:\n",
    "            seed = random.choice(list(self.model.keys()))\n",
    "        \n",
    "        result = seed\n",
    "        \n",
    "        for _ in range(length - self.order):\n",
    "            current_state = result[-self.order:]\n",
    "            if current_state not in self.model:\n",
    "                # If state not found, pick a random next character\n",
    "                next_char = random.choice('abcdefghijklmnopqrstuvwxyz ')\n",
    "            else:\n",
    "                next_char = random.choice(self.model[current_state])\n",
    "            result += next_char\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample text for training\n",
    "    sample_text = \"\"\"\n",
    "    The quick brown fox jumps over the lazy dog. \n",
    "    The dog sleeps while the fox runs swiftly.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create and train the generator\n",
    "    generator = MarkovTextGenerator(order=3)\n",
    "    generator.train(sample_text)\n",
    "    \n",
    "    # Generate text\n",
    "    generated_text = generator.generate(length=100)\n",
    "    print(\"Generated text:\")\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ae28da1-6462-4238-86bd-1ba0408a787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      " in a time there was a castle. She had a time there was a brave princess who lived in a dragon as her best friend and they went on many\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def build_markov_chain(text, n=1):\n",
    "    \"\"\"\n",
    "    Build a Markov chain model from the input text.\n",
    "\n",
    "    Parameters:\n",
    "    - text: str - input training text\n",
    "    - n: int - order of the Markov chain (default 1)\n",
    "\n",
    "    Returns:\n",
    "    - dict: a dictionary representing the Markov chain\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    markov_chain = {}\n",
    "\n",
    "    for i in range(len(words) - n):\n",
    "        key = tuple(words[i:i + n])\n",
    "        next_word = words[i + n]\n",
    "        \n",
    "        if key not in markov_chain:\n",
    "            markov_chain[key] = []\n",
    "        markov_chain[key].append(next_word)\n",
    "\n",
    "    return markov_chain\n",
    "\n",
    "def generate_text(chain, n=1, max_words=50):\n",
    "    \"\"\"\n",
    "    Generate text using the Markov chain.\n",
    "\n",
    "    Parameters:\n",
    "    - chain: dict - the Markov chain\n",
    "    - n: int - order of the Markov chain\n",
    "    - max_words: int - maximum number of words to generate\n",
    "\n",
    "    Returns:\n",
    "    - str: generated text\n",
    "    \"\"\"\n",
    "    # Randomly pick a starting key\n",
    "    start_key = random.choice(list(chain.keys()))\n",
    "    generated_words = list(start_key)\n",
    "\n",
    "    for _ in range(max_words - n):\n",
    "        current_key = tuple(generated_words[-n:])\n",
    "        next_words = chain.get(current_key)\n",
    "\n",
    "        if not next_words:\n",
    "            break  # Stop if there are no next words\n",
    "        next_word = random.choice(next_words)\n",
    "        generated_words.append(next_word)\n",
    "\n",
    "    return ' '.join(generated_words)\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"\"\"\n",
    "Once upon a time there was a brave princess who lived in a castle. \n",
    "She had a dragon as her best friend and they went on many adventures together.\n",
    "\"\"\"\n",
    "\n",
    "# Build the Markov chain with order 1\n",
    "chain = build_markov_chain(sample_text, n=1)\n",
    "\n",
    "# Generate text\n",
    "generated = generate_text(chain, n=1, max_words=30)\n",
    "print(\"Generated Text:\\n\", generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37b4e046-8093-4129-9a12-3d77aabdf973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creative text generations:\n",
      "1. !\n",
      "2. Colorful parrots mimic tiny ants carry mountain peaks mountain swift.\n",
      "3. Raccoons open carry.\n",
      "4. Clever quick foxes carry massive whales sing haunting!\n",
      "5. Lazy cats swift.\n",
      "6. Clever ravens solve complex swift swift massive leaves carry!\n",
      "7. Ancient trees whisper secrets through rustling leaves!\n",
      "8. Tiny ants brown dogs colorful parrots mimic human speech with uncanny accuracy.\n",
      "9. Tiny ...\n",
      "10. Massive whales curious raccoons mountain peaks with uncanny accuracy!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class CreativeMarkovGenerator:\n",
    "    def __init__(self, max_order=3):\n",
    "        self.max_order = max_order\n",
    "        self.models = {}  # Multiple models for different orders\n",
    "        self.vocab = set()\n",
    "        self.vectorizer = None\n",
    "        self.word_vectors = None\n",
    "\n",
    "    def train(self, text):\n",
    "        # Preprocess text\n",
    "        sentences = re.split(r'[.!?]\\s*', text)\n",
    "        sentences = [re.sub(r'[^\\w\\s]', '', s.lower()) for s in sentences if s.strip()]\n",
    "\n",
    "        # Train models for different orders and build vocabulary\n",
    "        for order in range(1, self.max_order + 1):\n",
    "            self.models[order] = defaultdict(dict)\n",
    "            for sentence in sentences:\n",
    "                words = sentence.split()\n",
    "                if len(words) < order:\n",
    "                    continue\n",
    "                padded = ['[START]'] * order + words + ['[END]']\n",
    "                for i in range(len(padded) - order):\n",
    "                    state = tuple(padded[i:i+order])\n",
    "                    next_word = padded[i+order]\n",
    "                    self.models[order][state][next_word] = self.models[order][state].get(next_word, 0) + 1\n",
    "                    self.vocab.add(next_word)\n",
    "\n",
    "        # Build semantic model after vocabulary is filled\n",
    "        self._build_semantic_model(sentences)\n",
    "\n",
    "    def _build_semantic_model(self, sentences):\n",
    "        # Semantic similarity model based on word co-occurrence\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.vectorizer.fit(list(self.vocab))\n",
    "        self.word_vectors = self.vectorizer.transform(list(self.vocab))\n",
    "\n",
    "    def _similar_words(self, word, n=3):\n",
    "        \"\"\"Find semantically similar words\"\"\"\n",
    "        if word not in self.vectorizer.vocabulary_:\n",
    "            return [word]\n",
    "\n",
    "        vec = self.vectorizer.transform([word])\n",
    "        if vec.shape[0] == 0 or vec.shape[1] == 0:\n",
    "            return [word]\n",
    "\n",
    "        sims = cosine_similarity(vec, self.word_vectors)\n",
    "        top_indices = np.argsort(sims[0])[-n-1:-1][::-1]\n",
    "        return [list(self.vocab)[i] for i in top_indices if i < len(self.vocab)]\n",
    "\n",
    "    def generate(self, temperature=0.8, max_length=15):\n",
    "        if not self.models:\n",
    "            return \"No model trained\"\n",
    "\n",
    "        current_order = random.randint(1, self.max_order)\n",
    "        state = random.choice([\n",
    "            s for s in self.models[current_order].keys()\n",
    "            if s[0] == '[START]'\n",
    "        ])\n",
    "\n",
    "        output = list(state)\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            if random.random() > 0.7:\n",
    "                current_order = random.randint(1, self.max_order)\n",
    "                state = tuple(output[-current_order:]) if len(output) >= current_order else state[:current_order]\n",
    "\n",
    "            if state not in self.models[current_order]:\n",
    "                current_order = max(1, current_order - 1)\n",
    "                state = tuple(output[-current_order:]) if len(output) >= current_order else state[:current_order]\n",
    "                if state not in self.models[current_order]:\n",
    "                    break\n",
    "\n",
    "            candidates = list(self.models[current_order][state].keys())\n",
    "            counts = list(self.models[current_order][state].values())\n",
    "\n",
    "            if temperature > 0.5 and random.random() > 0.6 and candidates:\n",
    "                candidates.extend(self._similar_words(random.choice(candidates)))\n",
    "                counts.extend([1] * 3)\n",
    "\n",
    "            weights = [count**(1/temperature) for count in counts]\n",
    "            next_word = random.choices(candidates, weights=weights, k=1)[0]\n",
    "\n",
    "            if next_word == '[END]':\n",
    "                break\n",
    "\n",
    "            output.append(next_word)\n",
    "            state = tuple(output[-current_order:])\n",
    "\n",
    "            # Occasionally combine with another phrase\n",
    "            if random.random() > 0.8 and len(output) < max_length / 2:\n",
    "                continuation = self.generate(\n",
    "                    temperature=min(1.5, temperature + 0.3),\n",
    "                    max_length=max_length // 2\n",
    "                )\n",
    "                output.extend(continuation.lower().split())\n",
    "                break\n",
    "\n",
    "        result = ' '.join([w for w in output if w != '[START]']).capitalize()\n",
    "        if not any(result.endswith(p) for p in '.!?'):\n",
    "            result += random.choice(['.', '!', '...'])\n",
    "\n",
    "        return result\n",
    "\n",
    "# Sample training text\n",
    "training_text = \"\"\"\n",
    "Quick foxes leap over fences while brown dogs chase their tails. \n",
    "Lazy cats nap in warm sunlight as eager puppies jump playfully. \n",
    "Ancient trees whisper secrets through rustling leaves. \n",
    "Hungry wolves hunt under moonlit skies. \n",
    "Busy bees gather golden pollen from fragrant flowers. \n",
    "Tiny ants carry massive leaves across the forest floor. \n",
    "Clever ravens solve complex puzzles with surprising intelligence. \n",
    "Swift deer escape lurking predators through dense thickets. \n",
    "Massive whales sing haunting melodies in ocean depths. \n",
    "Colorful parrots mimic human speech with uncanny accuracy. \n",
    "Curious raccoons open secured containers using nimble paws. \n",
    "Playful dolphins surf rolling waves near sunny shores. \n",
    "Majestic eagles soar above mountain peaks with effortless grace.\n",
    "\"\"\"\n",
    "\n",
    "# Generate samples\n",
    "generator = CreativeMarkovGenerator(max_order=3)\n",
    "generator.train(training_text)\n",
    "\n",
    "print(\"Creative text generations:\")\n",
    "for i in range(10):\n",
    "    temp = 0.7 + random.random() * 0.6  # Vary temperature\n",
    "    print(f\"{i+1}. {generator.generate(temperature=temp)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334bc12-2559-4f9d-9ea2-fd44fd43d733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04472802-ab0b-48c8-9654-9b4224a4a90c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ebba2-7a22-47f5-a5b2-e676b94d1565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119f032-f4e2-44ba-a762-0c49540e69af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c384d-4fe1-41e4-8fc4-ca159eb1b2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
