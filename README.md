This project implements a simple text generation algorithm using Markov Chains. The goal is to create a statistical model that learns the probability of each word (or character) following another based on patterns found in a given text.

 Key Features:
Builds a Markov chain model from input text.

Predicts the next word or character based on the current state.

Generates random but statistically relevant text sequences.

Lightweight and easy to understandâ€”no deep learning involved!

 Use Cases:
Generating random sentences in the style of a given text.

Learning the basics of probabilistic modeling in NLP.

Educational tool for understanding how simple text generation works.

This project offers a foundational understanding of how classic text generation works before diving into complex models like GPT.



